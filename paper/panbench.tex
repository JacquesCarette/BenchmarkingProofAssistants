\documentclass[a4paper,UKenglish,cleveref, autoref, thm-restate,anonymous]{lipics-v2021}
%This is a template for producing LIPIcs articles. 
%for A4 paper format use option "a4paper", for US-letter use option "letterpaper"
%for british hyphenation rules use option "UKenglish", for american hyphenation rules use option "USenglish"
%for section-numbered lemmas etc., use "numberwithinsect"
%for enabling cleveref support, use "cleveref"
%for enabling autoref support, use "autoref"
%for anonymousing the authors (e.g. for double-blind review), add "anonymous"
%for enabling thm-restate support, use "thm-restate"
%for producing a PDF according the PDF/A standard, add "pdfa"

%\pdfoutput=1 %uncomment to ensure pdflatex processing (mandatatory e.g. to submit to arXiv)
%\hideLIPIcs  %uncomment to remove references to LIPIcs series (logo, DOI, ...), e.g. when preparing a pre-final version to be uploaded to arXiv or another public repository

%\graphicspath{{./graphics/}}%helpful if your graphic files are in another directory

\usepackage{panbench}

\title{\panbench: A Comparative Benchmarking Tool for Dependently-Typed Languages}

\author{Reed Mullanix}{Department of Computing and Software, McMaster University, Canada}{mullanir@mcmaster.ca}{https://orcid.org/0000-0002-7970-4961}{}
\author{Jacques Carette}{Department of Computing and Software, McMaster University, Canada}{carette@mcmaster.ca}{https://orcid.org/0000-0001-8993-9804}{}

\authorrunning{R. Mullanix and J. Carette}

\Copyright{Reed Mullanix and Jacques Carette}

\ccsdesc[100]{\textcolor{red}{Replace ccsdesc macro with valid one}} %TODO mandatory: Please choose ACM 2012 classifications from https://dl.acm.org/ccs/ccs_flat.cfm 

\keywords{\textcolor{red}{Add keywords}} %TODO mandatory; please add comma-separated list of keywords

\category{} %optional, e.g. invited paper

\relatedversion{} %optional, e.g. full version hosted on arXiv, HAL, or other respository/website
%\relatedversiondetails[linktext={opt. text shown instead of the URL}, cite=DBLP:books/mk/GrayR93]{Classification (e.g. Full Version, Extended Version, Previous Version}{URL to related version} %linktext and cite are optional

%\supplement{}%optional, e.g. related research data, source code, ... hosted on a repository like zenodo, figshare, GitHub, ...
%\supplementdetails[linktext={opt. text shown instead of the URL}, cite=DBLP:books/mk/GrayR93, subcategory={Description, Subcategory}, swhid={Software Heritage Identifier}]{General Classification (e.g. Software, Dataset, Model, ...)}{URL to related version} %linktext, cite, and subcategory are optional

%\funding{(Optional) general funding statement \dots}%optional, to capture a funding statement, which applies to all authors. Please enter author specific funding statements as fifth argument of the \author macro.

%\nolinenumbers %uncomment to disable line numbering

%Editor-only macros:: begin (do not touch as author)%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\EventEditors{John Q. Open and Joan R. Access}
\EventNoEds{2}
\EventLongTitle{42nd Conference on Very Important Topics (CVIT 2016)}
\EventShortTitle{CVIT 2016}
\EventAcronym{CVIT}
\EventYear{2016}
\EventDate{December 24--27, 2016}
\EventLocation{Little Whinging, United Kingdom}
\EventLogo{}
\SeriesVolume{42}
\ArticleNo{23}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle

\begin{abstract}
We benchmark four proof assistants (\agda, \idris, \lean and \rocq) through a
single test suite. We focus our benchmarks on the basic features that all
systems based on a similar foundations (dependent type theory) have in common.
We do this by creating an ``over language'' in which to express all the
information we need to be able to output \emph{correct and idiomatic syntax}
for each of our targets. Our benchmarks further focus on ``basic engineering''
of these systems: how do they handle long identifiers, long lines, large
records, large data declarations, and so on.

Our benchmarks reveals both flaws and successes in all systems. We give a
thorough analysis of the results.

We also detail the design of our extensible system. It is designed so that
additional tests and additional system versions can easily be added. A side
effect of this work is a better understanding of the common abstract syntactic
structures of all four systems.
\end{abstract}

\section{Introduction}
\label{sec:intro}

\todo{this itemized list should be expanded into actual text}
\begin{itemize}
\item benchmark system engineering and scaling
\item benchmarking of anything resembling proofs would be a major research
project
\item the languages (of types/expressions and of declarations) of all 4
are quite similar in their surface expressivity, even though all possess a
myriad of specific features that are unshared
\end{itemize}

\section{Methodology}
\label{sec:method}

\todo[inline]{This is really documenting the 'experiment'. The actual details
of the thinking behind the design is in Section~\ref{sec:design}.}

\todo{this itemized list should be expanded into actual text}
\begin{itemize}
\item single language of tests
\item document the setup of tests, high level
\item document the setup of testing infrastructure, high level
\item linear / exponential scaling up of test 'size'
\end{itemize}

\section{Results}
\label{sec:results}

\section{Discussion}
\label{sec:discuss}

\section{The Design of \panbench}
\label{sec:design}

At its core, \panbench is a tool for producing grammatically well-formed concrete
syntax across multiple different languages. Crucially, \panbench does \emph{not}
require that the syntax produced is well-typed or even well-scoped: if it did,
then it would be impossible to benchmark how systems perform when they encounter
errors. This seemingly places \panbench in stark contrast with other software tools\todo{Reed: Cite something} for
working with the meta-theoretic properties of type systems, which are typically
concerned only with well-typed terms.

However, core task of \panbench is not that different from the task of a logical framework~\cite{Harper-Honsell-Plotkin:1993}:
Both systems exist to manipulate judgements, inference rules, and derivations: \panbench
just works with \emph{grammatical} judgements and production rules rather than typing judgments
and inference rules. In this sense \panbench is a \emph{Grammatical} framework rather than a logical
one.

This similarity let us build \panbench atop well-understood design 
principles. In particular, a mechanized logical framework typically
consists of two layers:

\begin{enumerate}
\item A layer for defining judgements \`{a}la relations.
\item A logic programming layer for synthesizing derivations.
\end{enumerate}

A user would then encode a language inside of the logical framework by laying out all of the
judgements, and then proving an adequacy theorem on the side that shows that their encoding
of the judgements actually aligns with the language. However, if one wanted to mechanize this
adequacy proof, then a staged\todo{Reed: Explain why staging matters} third layer that consists of a more traditional proof assistant would
be required.

If we take this skeleton of a design and transpose it to work with grammatical constructs
rather than logical ones, we will also obtain three layers:

\begin{enumerate}
\item A layer for defining grammars \`{a}la relations.
\item A logic programming layer for synthesizing derivations.
\item A staged functional programming layer for proving ``adequacy'' results.
\end{enumerate}

In this case, an adequacy result for a given language \(\mathcal{L}\) is a constructive proof that
all grammatical derivations written within the framework can be expressed within the
concrete syntax of a language \(\mathcal{L}\). However, the computational content of such a proof
essentially amounts to a compiler written in the functional programming layer.

\subsection{Implementing The Grammatical Framework}
\label{sec:framework-implementation}

Implementing a bespoke hybrid of a logic and functional programming language is
no small feat, and also requires prospective users to learn yet another single-purpose
tool. Luckily, there already exists a popular, industrial-grade hybrid logic/functional
programming language in wide use: GHC Haskell.

At first glance, Haskell does not contain a logic programming language. However,
if we enable enough GHC extensions, the typeclass system can be made \emph{just}
rich enough to encode a simply-typed logical framework. The key insight is that
we can encode each production rule using multi-parameter type classes with
a single method. Moreover, we can encode our constructive adequacy proofs for a
given set of production rules as instances that translate each of the productions
in the abstract grammar to productions in the syntax of an actual language.

As a concrete example, consider the grammar of the following simple imperative language.
\begin{grammar}
  <expr> := x \alt n \alt <expr> `+' <expr> \alt <expr> `*' <expr>
  
  <stmt> := <var> `=' <expr> \alt `while' <expr> `do' <stmt> \alt <stmt> `;' <stmt>
\end{grammar}

We can then encode this grammar with the following set of multi-parameter typeclasses:

\begin{lstlisting}[style=haskell]
class Var expr where
  var :: String -> expr

class Lit expr where
  lit :: Int -> expr

class Add expr where
  add :: expr -> expr -> expr

class Mul expr where
  mul :: expr -> expr -> expr

class Assign expr stmt where
  assign :: expr -> stmt

class While expr stmt where
  while :: expr -> stmt -> stmt

class AndThen stmt where
  andThen :: stmt -> stmt -> stmt
\end{lstlisting}

This style of language encoding is typically known as the untyped variant of \emph{finally tagless}\cite{Carette-Kiselyov-Shan:2009},
and is well-known technique. However, our encoding is a slight refinement of the usual tagless style.
In particular, we restrict ourselves to a single class per production rule, whereas other
tagless encodings often use a class per syntactic category. We will explore the reasoning behind
this more fine-grained approach in later sections\todo[inline]{Forward reference here when section is written}.

\subsection{Designing The Language}
\label{sec:language-design}

\todo[inline]{Reed: Too informal, just brain dumping.}

Now that we've fleshed out how we are going to encode our grammatical framework into our host language,
it's time to design our idealized abstract grammar. All of our host languages largely agree on a subset of
the grammar of non-binding terms: the difficulties lie with binding forms and top level definitions.

The difficulties with binding forms are two-fold. The first problem is that a binder in a production-grade
proof assistant carries a lot more information than just a variable name and a type. After a careful study
of our four intended target languages, we classified the various binding features along three separate axes:
binding arity, binding annotations, and binding modifiers.

Binding arities and annotations are relatively self-explanatory, and classify the number of names bound, along with
the type of annotation allowed. Our target languages all have their binding
arities falling into one of three classes: \(n\)-ary, unary, or nullary. We can similarly characterise annotations
into three categories: required, optional, or forbidden.

On the other hand, binding modifiers require a bit more explanation. A binding modifier captures features like
implicit arguments, which do not change the number of names bound nor their annotations, but rather how
those bound names get treated by the rest of the system. Features like irrelevant arguments in \agda
or quantities in \idris behave similarly: they do not change the shape of the binding. Currently,
\panbench only supports visibility-related modifiers, but we have designed the system so that it is
easy to extend with new modifiers.

\todo[inline]{Reed: Make table of examples!}

The question of top-level definitions is much thornier, and there seems to be less agreement on how
they ought to be structured. The largest source of divergence is type signatures. Languages that
prioritize dependent pattern matching typically opt to have standalone type signatures:
this allow for top-level pattern matches, which in turn makes it much easier to infer motives\cite{McBride-Mckinna:2004}.
Conversely, languages oriented around tactics typically opt for in-line type signatures and pattern-matching
expressions. This appears to be largely independent of Miranda/ML syntax split: Lean 4 borrows large parts of
its syntax from Haskell, yet still opts for in-line signatures.

This presents us with a design decision: should our idealized grammar use inline or standalone signatures?
As long as we can (easily) translate from one style to the other, we have a genuine decision to make.
We have opted for the former as standalone signatures offer variations that languages with inline
signatures cannot handle. As a concrete example, consider the following \agda declaration:

\begin{lstlisting}[style=agda]
  id : (A : Type) -> A -> A
  id B x = x
\end{lstlisting}

In particular, note that we have bound first argument to a different name. Translating this to a
corresponding \rocq declaration then forces us to choose to use either the name from the signature
or the term. Conversely, using in-line signatures does not lead us to having to make an unforced
choice when translating to a separate signature, as we can simply duplicate the name in both the
signature and term.

However, inline signatures are not completely without fault, and cause some edge cases with binding
modifiers. As an example, consider the following two variants of the identity function in \agda.

\begin{lstlisting}[style=agda]
  id : {A : Type} -> A -> A
  id x = x

  id' : {A : Type} -> A -> A
  id' {A} x = x 
\end{lstlisting}

Both definitions mark the \texttt{A} argument as an implicit, but the second definition \emph{also}
binds it in the declaration. When we pass to inline type signatures, we lose this extra layer of
distinction. To account for this, we were forced to refine the visibility modifier system to distinguish
between ``bound'' and ``unbound'' modifiers. This extra distinction has not proved to be too onerous in
practice, and we still believe that inline signatures are the correct choice for our application.

\todo[inline]{Reed: Present the panbench grammar in BNF}.
\todo[inline]{Reed: Talk about left-hand-sides}.

\section{Conclusion}
\label{sec:conc}

\bibliography{references}

\end{document}

