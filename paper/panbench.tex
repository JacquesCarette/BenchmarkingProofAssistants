\documentclass[a4paper,UKenglish,cleveref, autoref, thm-restate,anonymous]{lipics-v2021}
%This is a template for producing LIPIcs articles. 
%for A4 paper format use option "a4paper", for US-letter use option "letterpaper"
%for british hyphenation rules use option "UKenglish", for american hyphenation rules use option "USenglish"
%for section-numbered lemmas etc., use "numberwithinsect"
%for enabling cleveref support, use "cleveref"
%for enabling autoref support, use "autoref"
%for anonymousing the authors (e.g. for double-blind review), add "anonymous"
%for enabling thm-restate support, use "thm-restate"
%for producing a PDF according the PDF/A standard, add "pdfa"

%\pdfoutput=1 %uncomment to ensure pdflatex processing (mandatatory e.g. to submit to arXiv)
%\hideLIPIcs  %uncomment to remove references to LIPIcs series (logo, DOI, ...), e.g. when preparing a pre-final version to be uploaded to arXiv or another public repository

%\graphicspath{{./graphics/}}%helpful if your graphic files are in another directory

\usepackage{panbench}

\title{\panbench: A Comparative Benchmarking Tool for Dependently-Typed Languages}

\author{Reed Mullanix}{Department of Computing and Software, McMaster University, Canada}{mullanir@mcmaster.ca}{https://orcid.org/0000-0002-7970-4961}{}
\author{Jacques Carette}{Department of Computing and Software, McMaster University, Canada}{carette@mcmaster.ca}{https://orcid.org/0000-0001-8993-9804}{}

\authorrunning{R. Mullanix and J. Carette}

\Copyright{Reed Mullanix and Jacques Carette}

\ccsdesc[100]{\textcolor{red}{Replace ccsdesc macro with valid one}} %TODO mandatory: Please choose ACM 2012 classifications from https://dl.acm.org/ccs/ccs_flat.cfm 

\keywords{\textcolor{red}{Benchmarking, dependent types, testing}}

\category{} %optional, e.g. invited paper

\relatedversion{} %optional, e.g. full version hosted on arXiv, HAL, or other respository/website
%\relatedversiondetails[linktext={opt. text shown instead of the URL}, cite=DBLP:books/mk/GrayR93]{Classification (e.g. Full Version, Extended Version, Previous Version}{URL to related version} %linktext and cite are optional

%\supplement{}%optional, e.g. related research data, source code, ... hosted on a repository like zenodo, figshare, GitHub, ...
%\supplementdetails[linktext={opt. text shown instead of the URL}, cite=DBLP:books/mk/GrayR93, subcategory={Description, Subcategory}, swhid={Software Heritage Identifier}]{General Classification (e.g. Software, Dataset, Model, ...)}{URL to related version} %linktext, cite, and subcategory are optional

%\funding{(Optional) general funding statement \dots}%optional, to capture a funding statement, which applies to all authors. Please enter author specific funding statements as fifth argument of the \author macro.

%\nolinenumbers %uncomment to disable line numbering

%Editor-only macros:: begin (do not touch as author)%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\EventEditors{John Q. Open and Joan R. Access}
\EventNoEds{2}
\EventLongTitle{42nd Conference on Very Important Topics (CVIT 2016)}
\EventShortTitle{CVIT 2016}
\EventAcronym{CVIT}
\EventYear{2016}
\EventDate{December 24--27, 2016}
\EventLocation{Little Whinging, United Kingdom}
\EventLogo{}
\SeriesVolume{42}
\ArticleNo{23}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle

\begin{abstract}
We benchmark four proof assistants (\agda, \idris, \lean and \rocq) through a
single test suite. We focus our benchmarks on the basic features that all
systems based on a similar foundations (dependent type theory) have in common.
We do this by creating an ``over language'' in which to express all the
information we need to be able to output \emph{correct and idiomatic syntax}
for each of our targets. Our benchmarks further focus on ``basic engineering''
of these systems: how do they handle long identifiers, long lines, large
records, large data declarations, and so on.

Our benchmarks reveals both flaws and successes in all systems. We give a
thorough analysis of the results.

We also detail the design of our extensible system. It is designed so that
additional tests and additional system versions can easily be added. A side
effect of this work is a better understanding of the common abstract syntactic
structures of all four systems.
\end{abstract}

\section{Introduction}
\label{sec:intro}

Production-grade implementations of dependently typed programming languages
are complicated pieces of software that feature many intricate and potentially
expensive algorithms. As such, large amounts of engineering effort has been dedicated
to optimizing these components. Unfortunately, engineering time is a finite
resource, and this necessarily means that other parts of these systems
get comparatively less attention. This often results in easy-to-miss performance problems:
we have heard anecdotes from a proof assistant developer that a na\"ive \(O(n^{2})\)
fresh name generation algorithm used for pretty-printing resulted in 100x slowdowns
in some pathological cases.

This suggests that a benchmarking suite that focuses on these simpler components
could reveal some (comparatively) easy potential performance gains. Moreover, such
a benchmarking suite would also be valuable for developers of new dependently typed
languages, as it is much easier to optimize with a performance goal in mind. This
is an instance of the classic \(m \times n\) language tooling problem: constructing
a suite of \(m\) benchmarks for \(n\) languages directly requires a quadratic
amount of work up front, and adding either a new test case or a new language to
the suite requires an additional linear amount of effort.

Like most \(m \times n\) tooling problems, the solution is to introduce
a mediating tool. In our case, we ought to write all of the benchmarks
in an intermediate language, and then translate that intermediate language to
the target languages in question. There are existing languages like Dedukti~\cite{Dedukti:2023}
or Informath~\cite{Informath:2026}
that attempt to act as an intermediary between popular proof assistants, but these
tools typically focus on translating the \emph{content} of proofs, not exact
syntactic structure. To fill this gap, we have created the \panbench system, which consists of:

\begin{enumerate}
\item An extensible embedded Haskell DSL that encodes the concrete syntax of a
  typical dependently typed language.
\item A series of compilers for that DSL to \agda, \idris, \lean, and \rocq. \todo{Reed: Citations here}
\item A benchmarking harness that can perform sandboxed builds of
  multiple versions of \agda, \idris, \lean, and \rocq.
\item An incremental build system that can produce benchmarking reports as
  static HTML files or PGF plots\footnote{All plots in this paper were produced directly by \panbench.}.
\end{enumerate}


% Reed M, 13/02/2026:
% We discussed the main contributions, and settled on
% - Concrete benchmarking stats/graphs
% - Supporting infrastructure
% - The design of panbench qua DSL

% \todo{this itemized list should be expanded into actual text}
% \begin{itemize}
% \item benchmark system engineering and scaling
% \item benchmarking of anything resembling proofs would be a major research
% project
% \item the languages (of types/expressions and of declarations) of all 4
% are quite similar in their surface expressivity, even though all possess a
% myriad of specific features that are unshared
% \end{itemize}



\section{Methodology}
\label{sec:method}

\todo[inline]{This is really documenting the 'experiment'. The actual details
of the thinking behind the design is in Section~\ref{sec:design}.}

\todo{this itemized list should be expanded into actual text}
\begin{itemize}
\item single language of tests
\item document the setup of tests, high level
\item document the setup of testing infrastructure, high level
\item linear / exponential scaling up of test 'size'
\end{itemize}

\section{Results}
\label{sec:results}

Given that our test suite has \(32\) tests, each of which produces \(3\) different graphs, we have no
room to display all \(96\) resulting graphs\footnote{Nor can we have appendices!}. We thus choose results
that appear to be the most ``interesting''.

% Order:
% - very basic syntactic
% - long names of simple structures
% - nested structures
% - dependency
% - conversion
%
% Meta:
% - "get worse" is when the curve is not a straight line; these are log-log plots,
%     so that indicates exponential behaviour
% - system time variance hard to explain, though seems largely related to memory
%
% --------------
% Empty
% Meta: x-axis should not be log but uniform
% Comment: this is basically measuring start-up time, which varies a lot
%  - agda is very fast, lean is a bit slow, idris2 quite slow
%  - on max RSS, lean and idris2 are very greedy
% 
% Newlines
%
% - rocq and lean survive and only get measurably worse at n = 10^7
% - idris2 times out at the end
% - agda and idris2 get worse already at 10,000
% - memory goes up for all, but *much* worse for Agda/Idris2
% 
% Parens
%
% - there must a bug in lean's handling of parents: it is fine until 256 then dies
% - idris dies at 2^16, rocq at 2^14, while agda survives 2^16
% - (should compute slope of that straight line in idris2 and agda memory usage)
% 
% --------------
% 
% Meta: all LongName are fairly similar (good!) but still not entirely
%
% LongNameDatatype
%
% - idris2 handles quite smoothly until giant length
% - agda blows up much earlier
% - unknown why super-short length is (significantly) worse
% - lean's memory use is great, rest blow up, agda worst
% 
% LongNameDatatypeConstructor
% 
% - fairly similar (to above) except idris2 much more stable and rocq's memory use stabilizes
%
% LongNameDefinition
% 
% - similar to above but irdris2 blows up (didn't above(
%
% LongNameDefinitionLhs
%
% - idris2 now does not really blow up (though it starts to consume memory)
% - memory
% 
% LongNameDefinitionRhs
% 
% - same as above
%
% LongNameLambda
% 
% - long name lambda and Pi are 'the same', which is good (except for the blow up
%  of Agda and Idris2)
%
% LongNamePi
% 
% - see above
%
% - next 3 again follow same pattern
% LongNameRecord
% 
% LongNameRecordConstructor
% 
% LongNameRecordField
% 
% --------------
%
% DatatypeParameters
%
% - impressive performance (minus start-up) from idris2 and rocq
% - agda and lean "blow up" around size 30
% 
% LargeDependentRecord
%
% all systems get worse, following a similar path, 
% rest time out (lean at n=128, rest at n=256), only rocq survives
% memory use goes way way up
% 
% LargeIndexedDatatype
% 
% - all systems get worse, and all but rocq time out at n=256
% - Idris goes from its usual slow to timing out entirely with no transition
%
% LargeIndexedParameterisedDatatype
% 
% - idris2 rocks this one, with agda a close second
% - rocq explodes wrt memory, and lean on time
%
% LargeLambda
%
% - idris2 plateau unexplained; decrease in memory even more so
% - lean's spike?
% - agda suddenly blows up (seems to be memory related)
% 
% LargeSimpleDatatype
% 
% - idris2 does extremely well here
% - all others (slowly) get worse 
%
% LargeSimpleRecord
% 
% - idris2 does very well until the very end and blows up
% - agda and rocq handle very well
% - lean takes an increasingly large amount of time while rocq's memory blows up
% 
% ManyImplicits
% 
% - extremely weird idris2 behaviour: flat then spike
% - rocq and agda time curve up very gently, lean more seriously
% - rocq and agda start to consume more memory (from a very low level)
%
% * go up one more notch?
%
% Postulates
%
% - idris2 gets worse quickly, times out at 2^15
% - same for lean, times out earlier at 2^13
% - rocq and agda survive but seems to be in O(n^2) ? territory?
% 
% RecordParameters
% 
% - only rocq survives, rest die at 2^9
% - not clear what causes the problem
%
% SequentialDefinitions
% 
% - rocq clearly has worse definition (different slope), but memory behaviour is odd
% 
% SequentialDependentRecords
%
% - lean times out quickly, Idris eventually
% - none seem to "level out" to straight lines
% 
% SequentialSimpleRecords
%
% - idris2 seems to handle this extremely well
% - rest eventually starts to goblle memory
% - lean really does not handle this well at all
% 
% SimpleDataDefinitions
%
% - lean times out
% - same slope for rocq/agda and likely lean; not clear for idris2
% ----------------
% 
% NestedLet
% 
% - idris2 times out(n=1024), as does lean (n=512), rest do fine
%
% * another notch?
%
% NestedLetAdditions
% 
% - lots of tiem outs (agda, idris2 already after n=16), lean gets worse but survives,
%   rocq kills it
%
% NestedLetFunctions
% 
% - all systems blow up, at different points, as well as consume a lot of memory
% - lean, idris2 time out at n=128, agda at n=256, rocq survives
%
% IdChain
%
% - all systems blow up and time out (seems driven by memory use) between 8 and 16
%    except for lean, which uses no more memory at 32 and just a touch more time
% 
% ConversionAddition
% - Agda's higher time for the small case is unexplained
% - rocq is the only one that "blows up" with size
% 

\section{Discussion}
\label{sec:discuss}

The previous section analyzed the results themselves. Here we speculate on why the results may be as they
are. We comment on some particular results first, and then on what we find for each system.

\paragraph{General}

\paragraph{\agda}

\paragraph{\idris}

\paragraph{\lean}

\paragraph{\rocq}

\section{The Design of \panbench}
\label{sec:design}

At its core, \panbench is a tool for producing grammatically well-formed concrete
syntax across multiple different languages. Crucially, \panbench does \emph{not}
require that the syntax produced is well-typed or even well-scoped: if it did,
then it would be impossible to benchmark how systems perform when they encounter
errors. This seemingly places \panbench in stark contrast with other software tools\todo{Reed: Cite something} for
working with the meta-theoretic properties of type systems, which are typically
concerned only with well-typed terms.

However, the core task of \panbench is not that different from the task of
a logical framework~\cite{Harper-Honsell-Plotkin:1993}: Both
exist to manipulate judgements, inference rules, and derivations:
\panbench just works with \emph{grammatical} judgements and production
rules rather than typing judgments and inference rules. In this sense
\panbench is a \emph{grammatical} framework\footnote{Not to be
  confused with \emph{the} Grammatical Framework~\cite{Ranta:2011},
  which aims to be a more natural-language focused meta-framework for
  implementing and translating between grammars.  } rather than a
logical one.

This similarity let us build \panbench atop well-understood design 
principles. In particular, a mechanized logical framework typically
consists of two layers:

\begin{enumerate}
\item A layer for defining judgements \`{a} la relations.
\item A logic programming layer for synthesizing derivations.
\end{enumerate}

To use a logical framework, one first encodes a language by laying out all of the
judgements. Then, one needs to prove an adequacy theorem on the side that
shows that their encoding of the judgements actually aligns with the language. However, if
one wanted to mechanize this adequacy proof, then a staged third layer that consists of a more
traditional proof assistant would be required.

If we take this skeleton design and transpose it to work with grammatical constructs
rather than logical ones, we will also obtain three layers:

\begin{enumerate}
\item A layer for defining grammars as relations.
\item A logic programming layer for synthesizing derivations.
\item A staged functional programming layer for proving ``adequacy'' results.
\end{enumerate}

In this case, an adequacy result for a given language \(\mathcal{L}\) is a constructive proof that
all grammatical derivations written within the framework can be expressed within the
concrete syntax of a language \(\mathcal{L}\). However, the computational content of such a proof
essentially amounts to a compiler written in the functional programming layer. Given that this
compiler outputs \emph{concrete syntax}, it is implemented as a pretty-printer.

\subsection{Implementing The Grammatical Framework}
\label{sec:framework-implementation}

Implementing a bespoke hybrid of a logic and functional programming language is
no small feat, and also requires prospective users to learn yet another single-purpose
tool. Luckily, there already exists a popular, industrial-grade hybrid logic/functional
programming language in wide use: GHC Haskell.

At first glance, Haskell does not contain a logic programming language. However,
if we enable enough GHC extensions, the typeclass system can be made \emph{just}
rich enough to encode a simply-typed logical framework. The key insight is that
we can encode each production rule using multi-parameter type classes with
a single method. Moreover, we can encode our constructive adequacy proofs for a
given set of production rules as instances that translate each of the productions
in the abstract grammar to productions in the syntax of an actual language.

As a concrete example, consider the grammar of the following simple imperative language.
\begin{grammar}
  <expr> := x | n | <expr> `+' <expr> | <expr> `*' <expr>
  
  <stmt> := <var> `=' <expr> | `while' <expr> `do' <stmt> | <stmt> `;' <stmt>
\end{grammar}

We can then encode this grammar with the following set of multi-parameter typeclasses:

\begin{lstlisting}[style=haskell,caption={An example tagless encoding.}]
class Var expr where
  var :: String -> expr

class Lit expr where
  lit :: Int -> expr

class Add expr where
  add :: expr -> expr -> expr

class Mul expr where
  mul :: expr -> expr -> expr

class Assign expr stmt where
  assign :: String -> expr -> stmt

class While expr stmt where
  while :: expr -> stmt -> stmt

class AndThen stmt where
  andThen :: stmt -> stmt -> stmt
\end{lstlisting}

This style of language encoding is typically known as the untyped variant of \emph{finally tagless}~\cite{Carette-Kiselyov-Shan:2009}.
However, our encoding is a slight refinement where
we restrict ourselves to a single class per production rule. Other
tagless encodings often use a class per syntactic category. This more fine-grained approach
allows us to encode grammatical constructs that are only supported by a subset of our target
grammars; see section \ref{sec:language-design} for examples.

Unfortunately, the encoding above has some serious ergonomic issues. In particular, expressions
like \lstinline|assign "x" (lit 4)| will result in an unsolved metavariable for \lstinline|expr|,
as there may be multiple choices of \lstinline|expr| to use when solving the \lstinline|Assign ?expr stmt|
constraint. Luckily, we can resolve ambiguities of this form through judicious use of functional dependencies~\cite{Jones:2000},
as demonstrated below.

\begin{lstlisting}[style=haskell, caption={A tagless encoding with functional dependencies.}]
class Assign expr stmt | stmt -> expr where
  assign :: String -> expr -> stmt

class While expr stmt | stmt -> expr where
  while :: expr -> stmt -> stmt
\end{lstlisting}

\subsection{Designing The Language}
\label{sec:language-design}

Now that we've fleshed out how we are going to encode our grammatical framework into our host language,
it's time to design our idealized abstract grammar. All of our target languages roughly agree on a subset of
the grammar of non-binding terms: the main sources of divergence are binding
forms and top-level definitions\footnote{As we shall see in section
\ref{sec:top-level}, the syntactical divergence of top-level definitions is
essentially about binders as well.}.
This is ultimately unsurprising: dependent type theories are fundamentally theories of binding and
substitution, so we would expect some variation in how our target languages present the core of
their underlying theories.

This presents an interesting language design problem. Our idealized grammar will need
to find ``syntactic abstractions'' common between our four target languages.  Additionally,
we would also like for our solution to be (reasonably) extensible. Finding the core
set of grammatical primitives to accomplish this task is surprisingly tricky, and requires
a close analysis of the fine structure of binding.

\todo{JC: maybe a linguistic analogy would be useful? SVO vs SOV requires us to notice the
syntactic categories subject, object verb that are common to all, and that explicit renderings
merely differ in the order. Similarly for singular and plural as modifiers.}

\subsubsection{Binding Forms}
\label{sec:binding-form}

As users of dependently typed languages are well aware, a binding form carries much more information than
just a variable name and a type. Moreover, this extra information can have a large impact on typechecking
performance, as is the case with implicit/visible arguments. To further complicate matters, languages often offer
multiple syntactic options for writing the same binding form, as is evidenced by the prevalence of multi-binders
like \((x\ y\ z : A) \to B\). Though such binding forms are often equivalent to their single-binder counterparts
as \emph{abstract} syntax, they may have different performance characteristics, so we cannot simply lower them to a
uniform single-binding representation. To account for these variations, we have designed a sub-language dedicated solely
to binding forms. This language classifies the various binding features along three separate axes: binding arity,
binding annotations, and binding modifiers.

Binding arities and annotations are relatively self-explanatory, and classify the number of names bound, along with
the type of annotation allowed. Our target languages all have their binding arities falling into one of three classes:
\(n\)-ary, unary, or nullary. We can similarly characterise annotations into three categories: required, optional, or forbidden.

This language of binders is encoded in the implementation as a single class \lstinline|Binder| that is parameterised
by higher-kinded types \lstinline|arity :: Type -> Type| and \lstinline|ann :: Type -> Type|, and provide standardized
types for all three binding arities and annotations.  

\begin{lstlisting}[style=haskell,caption={The basic binding constructs in \panbench.}]
class Binder arity nm ann tm cell | cell -> nm tm where
  binder :: arity nm -> ann tm -> cell

-- | No annotation or arity.
data None nm = None
  
-- | A single annotation or singular arity.
newtype Single a = Single { unSingle :: a }

-- | Multi-binders.
type Multi = []

-- | Infix operator for an annotated binder with a single name.
(.:) :: (Binder Single nm Single tm cell) => nm -> tm -> cell
nm .: tp = binder (Single nm) (Single tp)

-- | Infix operator for an annotated binder.
(.:*) :: (Binder arity nm Single tm cell) => arity nm -> tm -> cell
nms .:* tp = binder nms (Single tp)
\end{lstlisting}
Production rules that involve binding forms are encoded as classes that are parametric
over a notion of a binding cell, as demonstrated below.
\begin{lstlisting}[style=haskell, caption={The \panbench class for \(\Pi\)-types.}]
class Pi cell tm | tm -> cell where
  pi :: [cell] -> tm -> tm
\end{lstlisting}

Decoupling the grammar of binding forms from the grammar of binders themselves allows us
to be somewhat polymorphic over the language of binding forms when writing generators.
This in turn means that we can potentially re-use generators when extending \panbench with
new target grammars that may support only a subset of the binding features present in
our four target grammars.

Binding modifiers, on the other hand, require a bit more explanation. A binding modifier captures features like
implicit arguments, which do not change the number of names bound nor their annotations, but rather how
those bound names get treated by the rest of the system. Currently,
\panbench only supports visibility-related modifiers, but we have designed the system so that it is
easy to extend with new modifiers; e.g. quantities in \idris or irrelevance annotations in \agda.

The language of binding modifiers is implemented as the following set of Haskell typeclasses.
\begin{lstlisting}[style=haskell,caption={Typeclasses for binding modifiers.}]
class Implicit cell where
  implicit :: cell -> cell

class SemiImplicit cell where
  semiImplicit :: cell -> cell
\end{lstlisting}

This is a case where the granular tagless encoding shines. Both \lean and \rocq have a form of semi-implicits\footnote{We use the term
  \emph{semi-implicit} argument to refer to an implicit argument that is not eagerly instantiated. In \rocq these are known as
  non-maximal implicits.}, whereas \idris and \agda have no such notion. Decomposing the language of binding
modifiers into granular pieces lets us write benchmarks that explicitly require support for features like semi-implicits.
Had we used a monolithic class that encodes the entire language of modifiers, we would have to resort to runtime errors
(or, even worse, dubious attempts at translation).

\subsubsection{Top-Level Definitions}
\label{sec:top-level}

The question of top-level definitions is much thornier, and there seems to be less agreement on how
they ought to be structured. Luckily, we can re-apply many of the lessons we learned in our treatment of binders;
after all, definitions are ``just'' top-level binding forms! This perspective lets us simplify how
we view some more baroque top-level bindings. As a contrived example, consider the following signature
for a pair of top-level \agda definitions.
\begin{lstlisting}[style=agda,caption={A complicated \agda signature.}]
private instance abstract @irr @mixed foo bar : Nat -> _
\end{lstlisting}
In our language of binders, this definition consists of a \(2\)-ary annotated binding
of the names \lstinline|foo|, \lstinline|bar| that has had a sequence of binding modifiers applied to it.

Unfortunately, this insight does not offer a complete solution. Notably, our four
target grammar differ significantly in how their treatment of type signatures.
prioritize dependent pattern matching (e.g. \agda, \idris) typically opt to have standalone type signatures:
this allow for top-level pattern matches, which in turn makes it much easier to infer motives\cite{McBride-Mckinna:2004}.
Conversely, languages oriented around tactics (e.g. \lean, \rocq) typically opt for in-line type signatures and pattern-matching
expressions. This appears to be largely independent of Miranda/ML syntax split: \lean borrows large parts of
its syntax from Haskell, yet still opts for in-line signatures.

This presents us with a design decision: should our idealized grammar use inline or standalone signatures?
As long as we can (easily) translate from one style to the other, we have a genuine decision to make.
We have opted for the former as standalone signatures offer variations that languages with inline
signatures cannot handle. As a concrete example, consider the following \agda declaration:

\begin{lstlisting}[style=agda,caption={A definition with mismatched names.}]
  id : (A : Type) -> A -> A
  id B x = x
\end{lstlisting}

In particular, note that we have bound the first argument to a different name. Translating this to a
corresponding \rocq declaration then forces us to choose to use either the name from the signature
or the term. Conversely, using in-line signatures does not lead us to having to make an unforced
choice when translating to a separate signature, as we can simply duplicate the name in both the
signature and term.

However, inline signatures are not completely without fault, and cause some edge cases with binding
modifiers. As an example, consider the following two variants of the identity function in \agda.
\label{listing:id}
\begin{lstlisting}[style=agda,caption={Two variants of the identity function.},label=lst:id]
  id : {A : Type} -> A -> A
  id x = x

  id' : {A : Type} -> A -> A
  id' {A} x = x 
\end{lstlisting}

Both definitions mark the \texttt{A} argument as an implicit, but the second definition \emph{also}
binds it in the declaration. When we pass to inline type signatures, we lose this extra layer of
distinction. To account for this, we were forced to refine the visibility modifier system to distinguish
between ``bound'' and ``unbound'' modifiers. This extra distinction has not proved to be too onerous in
practice, and we still believe that inline signatures are the correct choice for our application.

We have encoded this decision in our idealized grammar by introducing a notion of a ``left-hand-side''
of a definition, which consists of a collection of names to be defined, and a scope to define them
under. This means that we view definitions like Listing~\ref{lst:id} not as
functions \(\mathrm{id} : (A : \mathrm{Type}) \to A \to A\) but rather as \emph{bindings}
\(A : \mathrm{Type}, x : A \vdash \mathrm{id} : A\) in non-empty contexts.
This shift in perspective has the added benefit of making the interface to
other forms of parameterised definitions entirely uniform; for instance, a
parameterised record is simply just a record with a non-empty left-hand side.

In \panbench, definitions and their corresponding left-hand sides are encoded
via the following set of typeclasses.
\begin{lstlisting}[style=haskell, caption={Definitions and left-hand sides.}]
class Definition lhs tm defn | defn -> lhs tm where
  (.=) :: lhs -> tm -> defn

class DataDefinition lhs ctor defn | defn -> lhs ctor where
  data_ :: lhs -> [ctor] -> defn

class RecordDefinition lhs nm fld defn | defn -> lhs nm fld where
  record_ :: lhs -> name -> [fld] -> defn
\end{lstlisting}

\todo{JC: should have a closing sentence}
\section{Conclusion}
\label{sec:conc}

\bibliography{references}

% \section{Charts}

% \subsection{Empty}

% \input{pgfs/Empty/user.tex}
% \\
% \input{pgfs/Empty/system.tex}
% \\
% \input{pgfs/Empty/rss.tex}

% \subsection{ConversionAddition}
% \input{pgfs/ConversionAddition/user.tex}
% \\
% \input{pgfs/ConversionAddition/system.tex}
% \\
% \input{pgfs/ConversionAddition/rss.tex}

% \subsection{DatatypeParameters}
% \input{pgfs/DatatypeParameters/user.tex}
% \\
% \input{pgfs/DatatypeParameters/system.tex}
% \\
% \input{pgfs/DatatypeParameters/rss.tex}

% \subsection{IdChain}
% \input{pgfs/IdChain/user.tex}
% \\
% \input{pgfs/IdChain/system.tex}
% \\
% \input{pgfs/IdChain/rss.tex}

% \subsection{LargeDependentRecord}
% \input{pgfs/LargeDependentRecord/user.tex}
% \\
% \input{pgfs/LargeDependentRecord/system.tex}
% \\
% \input{pgfs/LargeDependentRecord/rss.tex}

% \subsection{LargeIndexedDatatype}
% \input{pgfs/LargeIndexedDatatype/user.tex}
% \\
% \input{pgfs/LargeIndexedDatatype/system.tex}
% \\
% \input{pgfs/LargeIndexedDatatype/rss.tex}

% \subsection{LargeIndexedParameterisedDatatype}
% \input{pgfs/LargeIndexedParameterisedDatatype/user.tex}
% \\
% \input{pgfs/LargeIndexedParameterisedDatatype/system.tex}
% \\
% \input{pgfs/LargeIndexedParameterisedDatatype/rss.tex}

% \subsection{LargeLambda}
% \input{pgfs/LargeLambda/user.tex}
% \\
% \input{pgfs/LargeLambda/system.tex}
% \\
% \input{pgfs/LargeLambda/rss.tex}

% \subsection{LargeSimpleDatatype}
% \input{pgfs/LargeSimpleDatatype/user.tex}
% \\
% \input{pgfs/LargeSimpleDatatype/system.tex}
% \\
% \input{pgfs/LargeSimpleDatatype/rss.tex}

% \subsection{LargeSimpleRecord}
% \input{pgfs/LargeSimpleRecord/user.tex}
% \\
% \input{pgfs/LargeSimpleRecord/system.tex}
% \\
% \input{pgfs/LargeSimpleRecord/rss.tex}

% \subsection{LongNameDatatype}
% \input{pgfs/LongNameDatatype/user.tex}
% \\
% \input{pgfs/LongNameDatatype/system.tex}
% \\
% \input{pgfs/LongNameDatatype/rss.tex}

% \subsection{LongNameDatatypeConstructor}
% \input{pgfs/LongNameDatatypeConstructor/user.tex}
% \\
% \input{pgfs/LongNameDatatypeConstructor/system.tex}
% \\
% \input{pgfs/LongNameDatatypeConstructor/rss.tex}

% \subsection{LongNameDefinition}
% \input{pgfs/LongNameDefinition/user.tex}
% \\
% \input{pgfs/LongNameDefinition/system.tex}
% \\
% \input{pgfs/LongNameDefinition/rss.tex}

% \subsection{LongNameDefinitionLhs}
% \input{pgfs/LongNameDefinitionLhs/user.tex}
% \\
% \input{pgfs/LongNameDefinitionLhs/system.tex}
% \\
% \input{pgfs/LongNameDefinitionLhs/rss.tex}

% \subsection{LongNameDefinitionRhs}
% \input{pgfs/LongNameDefinitionRhs/user.tex}
% \\
% \input{pgfs/LongNameDefinitionRhs/system.tex}
% \\
% \input{pgfs/LongNameDefinitionRhs/rss.tex}

% \subsection{LongNameLambda}
% \input{pgfs/LongNameLambda/user.tex}
% \\
% \input{pgfs/LongNameLambda/system.tex}
% \\
% \input{pgfs/LongNameLambda/rss.tex}

% \subsection{LongNamePi}
% \input{pgfs/LongNamePi/user.tex}
% \\
% \input{pgfs/LongNamePi/system.tex}
% \\
% \input{pgfs/LongNamePi/rss.tex}

% \subsection{LongNameRecord}
% \input{pgfs/LongNameRecord/user.tex}
% \\
% \input{pgfs/LongNameRecord/system.tex}
% \\
% \input{pgfs/LongNameRecord/rss.tex}

% \subsection{LongNameRecordConstructor}
% \input{pgfs/LongNameRecordConstructor/user.tex}
% \\
% \input{pgfs/LongNameRecordConstructor/system.tex}
% \\
% \input{pgfs/LongNameRecordConstructor/rss.tex}

% \subsection{LongNameRecordField}
% \input{pgfs/LongNameRecordField/user.tex}
% \\
% \input{pgfs/LongNameRecordField/system.tex}
% \\
% \input{pgfs/LongNameRecordField/rss.tex}

% \subsection{ManyImplicits}
% \input{pgfs/ManyImplicits/user.tex}
% \\
% \input{pgfs/ManyImplicits/system.tex}
% \\
% \input{pgfs/ManyImplicits/rss.tex}

% \subsection{NestedLet}
% \input{pgfs/NestedLet/user.tex}
% \\
% \input{pgfs/NestedLet/system.tex}
% \\
% \input{pgfs/NestedLet/rss.tex}

% \subsection{NestedLetAdditions}
% \input{pgfs/NestedLetAdditions/user.tex}
% \\
% \input{pgfs/NestedLetAdditions/system.tex}
% \\
% \input{pgfs/NestedLetAdditions/rss.tex}

% \subsection{NestedLetFunctions}
% \input{pgfs/NestedLetFunctions/user.tex}
% \\
% \input{pgfs/NestedLetFunctions/system.tex}
% \\
% \input{pgfs/NestedLetFunctions/rss.tex}

% \subsection{Newlines}
% \input{pgfs/Newlines/user.tex}
% \\
% \input{pgfs/Newlines/system.tex}
% \\
% \input{pgfs/Newlines/rss.tex}

% \subsection{Parens}
% \input{pgfs/Parens/user.tex}
% \\
% \input{pgfs/Parens/system.tex}
% \\
% \input{pgfs/Parens/rss.tex}

% \subsection{Postulates}
% \input{pgfs/Postulates/user.tex}
% \\
% \input{pgfs/Postulates/system.tex}
% \\
% \input{pgfs/Postulates/rss.tex}

% \subsection{RecordParameters}
% \input{pgfs/RecordParameters/user.tex}
% \\
% \input{pgfs/RecordParameters/system.tex}
% \\
% \input{pgfs/RecordParameters/rss.tex}

% \subsection{SequentialDefinitions}
% \input{pgfs/SequentialDefinitions/user.tex}
% \\
% \input{pgfs/SequentialDefinitions/system.tex}
% \\
% \input{pgfs/SequentialDefinitions/rss.tex}

% \subsection{SequentialDependentRecords}
% \input{pgfs/SequentialDependentRecords/user.tex}
% \\
% \input{pgfs/SequentialDependentRecords/system.tex}
% \\
% \input{pgfs/SequentialDependentRecords/rss.tex}

% \subsection{SequentialSimpleRecords}
% \input{pgfs/SequentialSimpleRecords/user.tex}
% \\
% \input{pgfs/SequentialSimpleRecords/system.tex}
% \\
% \input{pgfs/SequentialSimpleRecords/rss.tex}

% \subsection{SimpleDataDefinitions}
% \input{pgfs/SimpleDataDefinitions/user.tex}
% \\
% \input{pgfs/SimpleDataDefinitions/system.tex}
% \\
% \input{pgfs/SimpleDataDefinitions/rss.tex}

\end{document}

